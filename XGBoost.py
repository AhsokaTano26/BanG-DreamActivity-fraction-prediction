import pandas as pd
import numpy as np
import json
import ast
from datetime import timedelta
from sqlalchemy import create_engine, Column, Integer, String
from sqlalchemy.orm import sessionmaker
from sqlalchemy.ext.declarative import declarative_base
from sklearn.model_selection import train_test_split
from xgboost import XGBRegressor
from API.GetEventTracker import event_tracker
from API.GetEventInfo import get_event_info
from sklearn.metrics import mean_squared_error, r2_score

# --- æ•°æ®åº“ ORM å®šä¹‰ (ä¿æŒä¸å˜) ---
Base = declarative_base()


class Event(Base):
    __tablename__ = 'event'
    ID = Column(String(100), primary_key=True, nullable=False)
    EventID = Column(Integer)
    EventBand = Column(String(100))
    EventName = Column(String(100))
    EventType = Column(String(100))
    StartAt = Column(Integer)  # Unix æ—¶é—´æˆ³ (ms)
    EndAt = Column(Integer)  # Unix æ—¶é—´æˆ³ (ms)
    Rank = Column(Integer)
    PointRank = Column(String(100000))  # å­˜å‚¨ [{time, ep}, ...] åˆ—è¡¨çš„å­—ç¬¦ä¸²
    Country = Column(String(100))


# --- æ•°æ®åº“é…ç½® ---
DATABASE_URL = "sqlite:///data/db.sqlite3"
engine = create_engine(DATABASE_URL)
Base.metadata.create_all(engine)
Session = sessionmaker(bind=engine)


def parse_and_extract_features_for_ep_prediction(df: pd.DataFrame) -> pd.DataFrame:
    """
    è§£ææ•°æ®ï¼Œæå–ç‰¹å¾ï¼ˆæŒç»­æ—¶é—´ã€åˆ†ç±»ã€æ—¶é—´ï¼‰ï¼Œå¹¶å°†ç›®æ ‡å˜é‡
    è®¾ç½®ä¸ºæ´»åŠ¨ç»“æŸæ—¶çš„æ€»åˆ†æ•° (Total EP)ã€‚
    """

    # 1. ç›®æ ‡å˜é‡ï¼šæ´»åŠ¨ç»“æŸæ—¶çš„æœ€ç»ˆåˆ†æ•°
    # åˆå§‹åŒ–ç›®æ ‡ EP åˆ—
    df['Target_Total_EP'] = 0.0

    for index, row in df.iterrows():
        try:
            point_data = ast.literal_eval(row['PointRank'])
            if not point_data:
                continue

            # æœ€ç»ˆ EP æ˜¯ PointRank åˆ—è¡¨ä¸­çš„æœ€åä¸€ä¸ª 'ep' å€¼
            final_ep = point_data[-1]['ep']
            df.loc[index, 'Target_Total_EP'] = float(final_ep)

        except Exception as e:
            # print(f"å¤„ç†æ´»åŠ¨ ID={row['ID']} æ—¶çš„é”™è¯¯: {e}")
            continue

    # 2. ç‰¹å¾ï¼šæ´»åŠ¨æŒç»­æ—¶é—´ (Duration)
    # æŒç»­æ—¶é—´ (ç§’) æ˜¯æœ€é‡è¦çš„ç‰¹å¾
    df['Duration_S'] = (df['EndAt'] - df['StartAt']) / 1000

    # 3. å¤„ç†åˆ†ç±»ç‰¹å¾ (One-Hot Encoding)
    categorical_features = ['EventBand', 'EventType', 'Country']
    df_encoded = pd.get_dummies(df, columns=categorical_features, prefix=categorical_features).fillna(0)

    # 4. æå–æ—¶é—´ç‰¹å¾
    df_encoded['Start_Time'] = pd.to_datetime(df_encoded['StartAt'], unit='ms')
    df_encoded['DayOfWeek'] = df_encoded['Start_Time'].dt.dayofweek.astype(np.int64)
    df_encoded['HourOfDay'] = df_encoded['Start_Time'].dt.hour.astype(np.int64)

    return df_encoded


# --- å®Œæ•´ç¨‹åºä¸»æµç¨‹ (ä¿®æ”¹ä¸ºé¢„æµ‹ EP) ---

def run_ep_prediction_pipeline(session):
    """
    æ‰§è¡Œæ•°æ®åŠ è½½ã€ç‰¹å¾å·¥ç¨‹ã€æ¨¡å‹è®­ç»ƒå’Œè¯„ä¼°çš„å®Œæ•´æµç¨‹ï¼ˆç›®æ ‡ï¼šé¢„æµ‹ EPï¼‰ã€‚
    """
    # ----------------------------------------------------
    # A. æ•°æ®åŠ è½½
    # ----------------------------------------------------
    try:
        query = session.query(Event)
        query = query.filter(Event.Rank == 2000).filter(Event.EventID >= 250)
        data = [{c.name: getattr(e, c.name) for c in e.__table__.columns} for e in query]
        df_raw = pd.DataFrame(data)

        if df_raw.empty:
            print("ğŸš¨ æ•°æ®åº“ä¸­æœªæ‰¾åˆ°ä»»ä½•æ´»åŠ¨æ•°æ®ã€‚")
            return None, []

        print(f"âœ… æˆåŠŸåŠ è½½ {len(df_raw)} æ¡æ´»åŠ¨æ•°æ®ã€‚")

    except Exception as e:
        print(f"âŒ æ•°æ®åº“æŸ¥è¯¢å¤±è´¥: {e}")
        return None, []

    # ----------------------------------------------------
    # B. ç‰¹å¾å·¥ç¨‹
    # ----------------------------------------------------
    print("ğŸ”§ å¼€å§‹ç‰¹å¾å·¥ç¨‹...")
    # ä½¿ç”¨æ–°çš„ç‰¹å¾æå–å‡½æ•°
    df_features = parse_and_extract_features_for_ep_prediction(df_raw)

    # å®šä¹‰ç›®æ ‡åˆ—å’Œç‰¹å¾åˆ—
    target_col = 'Target_Total_EP'

    # æ˜ç¡®å®šä¹‰æ•°å€¼/æ—¶é—´ç‰¹å¾
    base_features = ['Duration_S', 'DayOfWeek', 'HourOfDay']

    # è‡ªåŠ¨è·å– One-Hot ç¼–ç ç‰¹å¾
    one_hot_cols = [
        col for col in df_features.columns
        if col.startswith(('EventBand_', 'EventType_', 'Country_'))
    ]

    # åˆå¹¶æ‰€æœ‰ç‰¹å¾åˆ—
    feature_cols = base_features + one_hot_cols
    feature_cols = [col for col in feature_cols if col in df_features.columns]

    X = df_features[feature_cols]
    y = df_features[target_col]

    print(f"âœ… ç‰¹å¾å·¥ç¨‹å®Œæˆã€‚é€‰å®šç‰¹å¾æ•°é‡: {len(feature_cols)}")
    print(f"ä½¿ç”¨çš„ç‰¹å¾åˆ—è¡¨: {feature_cols}")

    # ----------------------------------------------------
    # C. æ¨¡å‹è®­ç»ƒ
    # ----------------------------------------------------
    print("ğŸ¤– å¼€å§‹è®­ç»ƒ XGBoost æ¨¡å‹...")
    if X.empty:
        print("âŒ è®­ç»ƒé›†ä¸ºç©ºï¼Œæ— æ³•è®­ç»ƒæ¨¡å‹ã€‚")
        return None, []

    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    xgb_model = XGBRegressor(
        objective='reg:squarederror',
        n_estimators=300,
        learning_rate=0.03,
        max_depth=6,
        random_state=42,
        n_jobs=-1
    )

    xgb_model.fit(X_train, y_train)
    print("âœ… æ¨¡å‹è®­ç»ƒå®Œæˆã€‚")

    # ----------------------------------------------------
    # D. æ¨¡å‹è¯„ä¼°
    # ----------------------------------------------------
    y_pred = xgb_model.predict(X_test)

    # è¯„ä¼°æŒ‡æ ‡æ”¹ä¸º MSE å’Œ R2ï¼Œä½†è¡¡é‡çš„æ˜¯ EP å€¼çš„å·®å¼‚
    mse = mean_squared_error(y_test, y_pred)
    rmse = np.sqrt(mse)
    r2 = r2_score(y_test, y_pred)

    print("\n--- ğŸ“Š æ¨¡å‹è¯„ä¼°ç»“æœ ---")
    print(f"å‡æ–¹æ ¹è¯¯å·® (RMSE): {rmse:.2f} EP")
    print(f"å†³å®šç³»æ•° (R-squared): {r2:.4f}")

    # æ‰“å°ç‰¹å¾é‡è¦æ€§
    importances = pd.Series(xgb_model.feature_importances_, index=X.columns)
    print("\n--- ğŸ” æœ€é‡è¦çš„ 5 ä¸ªç‰¹å¾ ---")
    print(importances.nlargest(5))

    return xgb_model, X.columns


# ----------------------------------------------------
# E. è¿è¡Œæ•´ä¸ªç¨‹åº
# ----------------------------------------------------

if __name__ == '__main__':
    session = Session()
    Country_list = ["æ—¥æœ¬", "å›½é™…", "ä¸­å›½å°æ¹¾", "ä¸­å›½å¤§é™†", "éŸ©å›½"]

    # è®­ç»ƒæ¨¡å‹å¹¶è·å–ç‰¹å¾åˆ—è¡¨
    model, feature_names = run_ep_prediction_pipeline(session)

    # --- é¢„æµ‹æ–°æ´»åŠ¨æ€»åˆ†æ•° ---

    if model is not None and len(feature_names) > 0:
        print("\n--- ğŸ”® æ–°æ´»åŠ¨æ€»åˆ†æ•°é¢„æµ‹ ---")


        # å®é™… API è°ƒç”¨ï¼ˆä½¿ç”¨ Mock å‡½æ•°ä»£æ›¿ï¼‰
        # å‡è®¾æ´»åŠ¨ ID 293ï¼Œå›½å®¶ ID 3
        info, startAt, endAt = get_event_info(Activity=293, Country=3)

        # å‡†å¤‡æ–°æ´»åŠ¨çš„ç‰¹å¾
        new_activity_start_at = int(startAt)
        new_activity_end_at = int(endAt)
        new_activity_band = 'B'  # å‡è®¾æ˜¯ B å›¢
        new_activity_type = info['eventType']
        new_activity_country = Country_list[3]  # ä¸­å›½å¤§é™†

        # 1. åˆ›å»ºæ–°æ´»åŠ¨çš„ç‰¹å¾ DataFrame
        new_X = pd.DataFrame(0.0, index=[0], columns=feature_names)

        # 2. å¡«å……æ•°å€¼ç‰¹å¾ï¼šæŒç»­æ—¶é—´
        duration_s = (new_activity_end_at - new_activity_start_at) / 1000
        if 'Duration_S' in feature_names:
            new_X.loc[0, 'Duration_S'] = duration_s

        # 3. å¡«å……æ—¶é—´ç‰¹å¾
        start_time_dt = pd.to_datetime(int(new_activity_start_at), unit='ms')

        if 'DayOfWeek' in feature_names:
            new_X.loc[0, 'DayOfWeek'] = start_time_dt.dayofweek
        if 'HourOfDay' in feature_names:
            new_X.loc[0, 'HourOfDay'] = start_time_dt.hour

        # 4. å¡«å…… One-Hot ç¼–ç ç‰¹å¾
        band_col = f'EventBand_{new_activity_band}'
        type_col = f'EventType_{new_activity_type}'
        country_col = f'Country_{new_activity_country}'

        if band_col in feature_names:
            new_X.loc[0, band_col] = 1.0
        if type_col in feature_names:
            new_X.loc[0, type_col] = 1.0
        if country_col in feature_names:
            new_X.loc[0, country_col] = 1.0

        # 5. é¢„æµ‹
        predicted_ep = model.predict(new_X)[0]  # è¿™æ˜¯ä¸€ä¸ª numpy.float32/64 ç±»å‹

        print(f"æ´»åŠ¨å¼€å§‹æ—¶é—´: {start_time_dt}")
        print(f"æ´»åŠ¨ç»“æŸæ—¶é—´: {pd.to_datetime(int(new_activity_end_at), unit='ms')}")
        print(f"æ´»åŠ¨æŒç»­æ—¶é—´: {duration_s / 3600:.2f} å°æ—¶ ({duration_s:.0f} ç§’)")
        print(f"---")
        print(f"é¢„æµ‹æ´»åŠ¨æ€»åˆ†æ•° (Total EP): {predicted_ep.item():.0f}")

    session.close()